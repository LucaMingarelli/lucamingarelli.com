<!DOCTYPE html>
<html>
<head>
    <!-- Oribi Analytics -->
    <script type="application/javascript">
        (function(b,o,n,g,s,r,c){if(b[s])return;b[s]={};b[s].scriptToken="XzgzMjUyODI5Ng";b[s].callsQueue=[];b[s].api=function(){b[s].callsQueue.push(arguments);};r=o.createElement(n);c=o.getElementsByTagName(n)[0];r.async=1;r.src=g;r.id=s+n;c.parentNode.insertBefore(r,c);})(window,document,"script","https://cdn.oribi.io/XzgzMjUyODI5Ng/oribi.js","ORIBI");
    </script>
    <!-- End Oribi Analytics -->
    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-NLJ2P23');</script>
    <!-- End Google Tag Manager -->
    <title>Luca Mingarelli</title>
    <link rel="icon" href="../Icons/stork.png" type="image/png">
    <style>
        .collapsible {background-color: #777;color: white;cursor: pointer;  padding: 2px;width: 100%;
            border: none;  text-align: left;  outline: none;  font-size: 15px; border-radius: 2px;}
        /*.active,*/
        .collapsible:hover {  background-color: #555;}
        .content {display: none;  overflow: hidden;  background-color: #DCDCDC;}
    </style>
</head>

<!--<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>-->
<script>window.MathJax = {tex: {tags: 'ams'}};</script>
<script id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<!--<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_SVG"></script>-->
<script src="https://d3js.org/d3.v7.min.js"></script>

<link rel="stylesheet" href="prism/prism.css"> <!-- For code highlight -->
<script src="prism/prism.js"></script>         <!-- For code highlight -->


<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="../css/w3.css">
<link rel="stylesheet" href="../css/font.css">
<link rel="stylesheet" href="../css/responsiveiframe.css">
<script src="../js/style_preamble.js"></script>

<body class="w3-light-grey w3-content" style="max-width:2600px">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NLJ2P23"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- NavigationBar -->
<script src="js/Navbar.js"></script>
<!-- _____________ -->
<!-- PRE_CONTENT -->
<script src="js/pre_content.js"></script>
<!-- _____________ -->




<div class="w3-content w3-justify" style="max-width:800px">

    <h1 style="text-align: left;"><b>Correlation for binary variates</b></h1>

    For convenience, one often desires to summarise
    the dependency structure of a multivariate distribution
    with a single scalar metric. The most common measures is
    linear correlation. However this metric is known to have its
    severe pitfalls in many general cases, and better measures should be considered.

    <br><br>
    <div>
        <label for="p2-slider">Select \(p_Y\): </label>
        <input type="range" id="p2-slider" min="0" max="1" step="0.01" value="0.5">
        <span id="p2-value">0.5</span>
    </div>
    <br>
    <svg width="600" height="400"></svg>

    <script>
        const svg = d3.select("svg"),
              margin = { top: 20, right: 30, bottom: 40, left: 50 },
              width = +svg.attr("width") - margin.left - margin.right,
              height = +svg.attr("height") - margin.top - margin.bottom;

        const xScale = d3.scaleLinear().domain([0, 1]).range([0, width]);
        const yScale = d3.scaleLinear().domain([-1, 1]).range([height, 0]);

        const g = svg.append("g").attr("transform", `translate(${margin.left},${margin.top})`);
        
        g.append("g").attr("transform", `translate(0,${height})`).attr("class", "axis").call(d3.axisBottom(xScale));
        g.append("g").attr("class", "axis").call(d3.axisLeft(yScale));
        
        g.append("svg:foreignObject")
            .attr("class", "axis-label")
            .attr("x", width / 2)
            .attr("y", height + 35)
            // .style("text-anchor", "middle")
            .append("xhtml:div")
            .text("\\(p_X\\)");

        g.append("text")
            .attr("class", "axis-label")
            .attr("transform", "rotate(-90)")
            .attr("x", -height / 2)
            .attr("y", -40)
            .style("text-anchor", "middle")
            .text("\\rho");

        const lineMin = g.append("path").attr("fill", "none").attr("stroke", "blue").attr("stroke-width", 2);
        const lineMax = g.append("path").attr("fill", "none").attr("stroke", "red").attr("stroke-width", 2);

        // Add legend
        const legend = svg.append("g").attr("transform", `translate(${width - 100}, 20)`);
        
        legend.append("rect").attr("x", 0).attr("y", 0).attr("width", 12).attr("height", 12).attr("fill", "blue");
        legend.append("text").attr("x", 20).attr("y", 10).attr("class", "legend mathjax-label")
              .append("xhtml:div")
              .text("phi_{min}");
        
        legend.append("rect").attr("x", 0).attr("y", 20).attr("width", 12).attr("height", 12).attr("fill", "red");
        legend.append("text").attr("x", 20).attr("y", 30).attr("class", "legend mathjax-label")
              .append("xhtml:div")    
              .text("\\( \\phi_{\\text{max}} \\)");

        function computePhi(p1, p2) {
            let q1 = 1 - p1, q2 = 1 - p2;
            let phiMin = Math.max(-Math.sqrt((p1 * p2) / (q1 * q2)), -Math.sqrt((q1 * q2) / (p1 * p2)));
            let phiMax = Math.min(Math.sqrt((p1 * q2) / (p2 * q1)), Math.sqrt((p2 * q1) / (p1 * q2)));
            return { phiMin, phiMax };
        }

        function updatePlot(p2) {
            let data = d3.range(0, 1.01, 0.001).map(p1 => {
                let { phiMin, phiMax } = computePhi(p1, p2);
                return { p1, phiMin, phiMax };
            });
            
            lineMin.datum(data)
                .attr("d", d3.line()
                    .x(d => xScale(d.p1))
                    .y(d => yScale(d.phiMin)));
            
            lineMax.datum(data)
                .attr("d", d3.line()
                    .x(d => xScale(d.p1))
                    .y(d => yScale(d.phiMax)));
            
            MathJax.Hub.Queue(["Typeset", MathJax.Hub, document.querySelectorAll(".mathjax-label")]);
        }

        d3.select("#p2-slider").on("input", function() {
            let p2 = +this.value;
            d3.select("#p2-value").text(p2.toFixed(2));
            updatePlot(p2);
        });
        
        updatePlot(0.5);
    </script>


    <h2 style="text-align: left;">Linear correlation</h2>
    The first measure of dependency we encounter is Pearson's coefficient of
    linear correlation:
    <div style="overflow-x: auto; overflow-y: hidden;">
    \begin{equation}
    \begin{split}
    \rho(X_1, X_2) &= \frac{\text{cov}(X_1, X_2)}{\sigma_{X_1} \sigma_{X_2}} \\
    &= \frac{\mathbb{E}((X_1-\mathbb{E}X_1)(X_2-\mathbb{E}X_2))}{\sqrt{\mathbb{E}((X_1-\mathbb{E}X_1)^2)}\sqrt{\mathbb{E}((X_2-\mathbb{E}X_2)^2)}}
    \end{split}.
    \label{eq:lin_corr}
    \end{equation}
        </div>
    While very useful in many linear or approximately linear scenarios, this metric however fails
    to capture fundamental properties of more complex and realistic distributions.
    In addition, thinking in terms of linear correlation can easily make us prey of insidious
    pitfalls and fallacies.
    <br>
    First of all we notice that \eqref{eq:lin_corr} depends on the marginals
    and in particular, that it is well defined if and only if the second moments exist,
    \(\mathbb{E}(X_j)^2<\infty,\ \forall j\). Therefore this metric is not well defined
    for a number of marginals such as many power-law distributions where the second moment does not exist.
    <br>
    Moreover, the linear correlation \eqref{eq:lin_corr} is also unable to capture
    strong non-linear functional dependencies such as \(X_2=X_1^2\) or \(X_2 = \sin(X_1)\).
    Indeed in general one has \(|\rho|\le 1\) and \(|\rho|=1\iff X_2 = aX_1+b\)
    for some \(a\in\mathbb{R}\backslash \{0\},\ b\in\mathbb{R} \).
    <br>
    The linear correlation \(\rho\) is also invariant under strictly increasing
    <u>linear</u> transformation, but not under more general stricly increasing transformations.

    <br>
    One further source of confusion arise from us being used to reason in terms of
    normal distributions. Indeed a number of seemingly intuitive statements on
    correlations which are true in the case of normal distributions do not generalise outside of this distribution.
    <br>
    As an example, for normal distributions one finds zero correlation and independence equivalent, which
    is no longer true already for e.g. student-t distributed random variables.
    <br>
    Another fallacy is to think that the marginals and the correlations matrix
    (\(F_1\), \(F_2\), and \(\rho\) in the bivariate case) are sufficient to determine
    the joint distribution \(F\). This is true for elliptical distributions, but wrong in general.
    Indeed the only mathematical object encoding all information concerning the dependency structure
    is the copula itself.
    <br>
    Yet another fallacy is to think two marginals \(F_1\), \(F_2\),
    any value of \(\rho\in[-1,1]\) is attainable. Again, this is true for elliptically
    distributed \((X_1, X_2)\) with finite second moment, but wrong in general.
    The attainable range can be computed via <i>Hoeffding's formula</i>
    <div style="overflow-x: auto; overflow-y: hidden;">
    \begin{equation}
    \text{cov}(X_1, X_2) = \int_{-\infty}^\infty\int_{-\infty}^\infty C(F_1(x_1), F_2(x_2))-F_1(x_1)F_2(x_2)\text{d} x \text{d} y,
    \label{eq:Hoeffding_formula}
    \end{equation}
        </div>
    where \(\rho_{\text{min}}\) is attained for \(C=W_{\text{counter}}\) and \(\rho_{\text{max}}\) for \(C=C_{\text{co}}\).
    This can be arbitrarily small for appropriate choices of the marginals \(F_1\) and \(F_2\).

    <figure>
        <img class="center" alt="tail_dependence"
             src="img/Dependence/attainable_corr.svg"
             width="80%" >
        <figcaption><i><b>Fig.1:</b> Attainable range \([\rho_{\text{min}}, \rho_{\text{max}}]\)
            of the linear correlation coefficient for two random variables
            \(\log X_1 \sim \mathcal{N}(0,1)\) and \(\log X_2 \sim \mathcal{N}(0,\sigma^2)\).
        See <a href="#ref1">[1]</a> for more details.
        </i></figcaption>
    </figure>


    <hr class="w3-opacity">

    <h6>Exercise 1</h6>
    Consider two independent random variables \(Z, W \sim \mathcal{N}(0,1)\).
    The random variables \(X=Z\) and \(Y = ZW\) are clearly not independent.
    What's \(\rho(X, Y)\)?
    <br>
    <button class="collapsible" style="margin-bottom: 10px;margin-top: 10px">Solution 1</button>
    <div class="content" style="background-color: rgba(85,203,253,0.12) ; padding: 20px; border: 2px solid #9cc5ff;">
        The linear correlation coefficient is
        \begin{align*}
        \rho(X, Y) &= \text{cov}(X, Y) \newline
        &= \mathbb{E}(XY)\newline
        &= \mathbb{E}(W)\mathbb{E}(Z^2) = 0
        \end{align*}
        <p align="right"> ◻</p>
    </div>

    <h6>Exercise 2</h6>
    Prove \eqref{eq:Hoeffding_formula}.
    <br>
    <button class="collapsible" style="margin-bottom: 10px;margin-top: 10px">Solution 2</button>
    <div class="content" style="background-color: rgba(85,203,253,0.12) ;
    padding: 20px; border: 2px solid #9cc5ff;overflow-x: auto;">
        Start by considering an \(X_j, Y_j \sim F_j\),
        with \(X_j \perp\!\!\!\perp Y_j\), for \(j\in\{1,2\}\).
        One has:
        \begin{align*}
        2\text{cov}(X_1, X_2) &= \mathbb{E}((X_1-\mathbb{E}X_1)(X_2-\mathbb{E}X_2)) + \mathbb{E}((Y_1-\mathbb{E}Y_1)(Y_2-\mathbb{E}Y_2)) \newline
        &=\mathbb{E}\left(((X_1 - \mathbb{E}X_1)-(Y_1 - \mathbb{E}Y_1))((X_2 - \mathbb{E}X_2)-(Y_2 - \mathbb{E}Y_2))\right) \newline
        &= \mathbb{E}((X_1-Y_1)(X_2-Y_2)).
        \end{align*}
        Now recall that for any \(a,b\in\mathbb{R}\) one has
        \[
        b-a = \int_{-\infty}^\infty \Theta(x-a) - \Theta(x-b)\text{d}x,
        \]
        with \(\Theta(x)\) indicating Heaviside's theta function
        (with the convention \(\Theta(0)=1\)). Therefore:
        \begin{align*}
        2\text{cov}(X_1, X_2) &=
        \mathbb{E}\int_{-\infty}^\infty\int_{-\infty}^\infty
        (\Theta(x_1-Y_1) - \Theta(x_1-X_1))(\Theta(x_2-Y_2) - \Theta(x_2-X_2))
        \text{d}x_1\text{d}x_2 \newline
        \xrightarrow[]{\text{Fubini}}&=\int_{-\infty}^\infty\int_{-\infty}^\infty
        \mathbb{E}\left((\Theta(x_1-Y_1) - \Theta(x_1-X_1))(\Theta(x_2-Y_2) - \Theta(x_2-X_2))\right)
        \text{d}x_1\text{d}x_2\newline
        &=2\int_{-\infty}^\infty\int_{-\infty}^\infty F(x_1, x_2) - F_1(x_1)F_2(x_2)\text{d}x_1\text{d}x_2.
        \end{align*}
        <p align="right"> ◻</p>
    </div>

    <hr class="w3-opacity">
    <br>

    <h4 id="REFERENCES"><i>References</i></h4>

    [1] <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.321.5607&rep=rep1&type=pdf" id="ref1"> "Correlation and Dependence in Risk Management: Properties and Pitfalls", Paul Embrechts, Alexander McNeil, and Daniel Straumann, 1999</a>
    <br>
    [2] <a href="https://www.wired.com/2009/02/wp-quant/" id="ref2"> "Recipe for Disaster: The Formula That Killed Wall Street", Felix Salmon, February 2009, Wired Magazine</a>
    <br>
    [3] <a href="http://www.macs.hw.ac.uk/~cd134/2010/donemb.pdf" id="ref3"> "The devil is in the tails: actuarial mathematics and the subprime mortgage crisis", Catherine Donnelly and Paul Embrechts, 2010,  ASTIN Bulletin: The Journal of the IAA, 40(1), 1-33</a>
    <br>
    [4] <a href="http://www.ressources-actuarielles.net/EXT/ISFA/1226.nsf/9c8e3fd4d8874d60c1257052003eced6/34e84cb615c8b4eac12575fe006a9759/$FILE/li.defaultcorrelation.pdf" id="ref4">  "On Default Correlation: A Copula Function Approach", David X. Li, April 2000, The RiskMetrics Group Working Paper Number 99-07</a>
    <br>
    [5] <a href="https://web.archive.org/web/20091123165401/http://www.fsa.gov.uk/pubs/other/turner_review.pdf" id="ref5"> "The Turner Review", Turner, J. A., March 2009,  Financial Services Authority, UK </a>
    <br><br>


<!--MORE INTERESTING LINKS-->
<!--    http://samueldwatts.com/wp-content/uploads/2016/08/Watts-Gaussian-Copula_Financial_Crisis.pdf-->


    <!-- ________________________________________________________________________________________________ -->
    <!-- ________________________________________________________________________________________________ -->
    <!-- ________________________________________________________________________________________________ -->
    <!--    <h7>-->
    <!-- <span style="float:right;">
   <a href="./L2.html"><b><img src="../Icons/next.png" width="20px" align="right">Next</b></a>
   </span>
   </h7>
   <br> -->

    <h5> <a href="../Teaching.html"><b><img src="../Icons/back.png" width="20px"> Back to Teaching</b></a></h5>



    <hr class="w3-opacity">
</div>
</div>
<script type="text/javascript" src="../js/footer.js"></script>

<!-- End page content -->
</div>

<script src="../js/OpenCloseSidebar.js"></script>
<!--<script src="../js/ModalImageGallery.js"></script>-->
<script src="../js/OpenCloseCollapsible.js"></script>

</body>
</html>
