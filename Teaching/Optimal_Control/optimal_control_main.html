<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Oribi Analytics -->
  <script type="application/javascript">
    (function(b,o,n,g,s,r,c){if(b[s])return;b[s]={};b[s].scriptToken="XzgzMjUyODI5Ng";b[s].callsQueue=[];b[s].api=function(){b[s].callsQueue.push(arguments);};r=o.createElement(n);c=o.getElementsByTagName(n)[0];r.async=1;r.src=g;r.id=s+n;c.parentNode.insertBefore(r,c);})(window,document,"script","https://cdn.oribi.io/XzgzMjUyODI5Ng/oribi.js","ORIBI");
  </script>
  <!-- End Oribi Analytics -->
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
            new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
          j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
          'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-NLJ2P23');</script>
  <!-- End Google Tag Manager -->
  <meta charset="utf-8"/>
  <title>Luca Mingarelli</title>
  <link rel="icon" href="../../Icons/stork.png" type="image/png">
  <style>
    .collapsible {background-color: #777;color: white;cursor: pointer;  padding: 2px;width: 100%;
      border: none;  text-align: left;  outline: none;  font-size: 15px; border-radius: 2px;}
    /*.active,*/
    .collapsible:hover {  background-color: #555;}
    .content {display: none;  overflow: hidden;  background-color: #DCDCDC;}
  </style>

</head>

<!--<script src="https://cdn.plot.ly/plotly-latest.min.js"></script>-->
<script>window.MathJax = {tex: {tags: 'ams'}};</script>
<script id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<!--<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_SVG"></script>-->

<link rel="stylesheet" href="../../PRISM/prism.css"> <!-- For code highlight -->
<script src="../../PRISM/prism.js"></script>         <!-- For code highlight -->


<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="../../css/w3.css">
<link rel="stylesheet" href="../../css/font.css">
<link rel="stylesheet" href="../../css/responsiveiframe.css">
<script src="../../js/style_preamble.js"></script>

<body class="w3-light-grey w3-content" style="max-width:2600px">
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-NLJ2P23"
                  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
<!-- NavigationBar -->
<script src="../js/Navbar.js"></script>
<!-- _____________ -->
<!-- PRE_CONTENT -->
<script src="../js/pre_content.js"></script>
<!-- _____________ -->


<!-- Load d3.js -->
<script src="https://d3js.org/d3.v4.js"></script>



<div class="w3-content w3-justify" style="max-width:800px">

  <h1 style="text-align: left;"><b>Optimal Control Theory</b></h1>

<!--  <h2 style="text-align: left;"><b>The <i>efficiency-generality</i> trade-off</b></h2>-->

<h2 style="text-align: left;"><b>Defining the Problem</b></h2>
  

  <b>Definition 1 — Control function</b><blockquote><i> 
    A <strong>control function</strong>
    \(\mathbf{\gamma}(t)\) is a map from time \(t\in [0, \infty)\) to the set of <i>admissable controls</i> \(\Gamma\).
    <br>
    The control is also called a <strong>policy</strong>.
    
    </blockquote></i>
    <br>

    <b>Definition 2 — Controlled Dynamical System</b><blockquote><i> A system whose dynamics is described by the equation of motion
      
      \begin{equation}
      \dot{\mathbf{x}}(t)=\mathbf{f}(\mathbf{x}(t), \mathbf{\gamma}(t), t),
      \end{equation}
      
      is called a <strong>\(\mathbf{\gamma}\)-Controlled Dynamical System</strong>. 
      <br>
      A system which does not explicitely depent on time 
  
      \begin{equation}
      \dot{\mathbf{x}}(t)=\mathbf{f}(\mathbf{x}(t), \mathbf{\gamma}(t)),
      \end{equation}

      is called <strong>Autonomous</strong>.
      <br>
      The <strong>state</strong> of the system \(\mathbf{x}(t)\in \mathbb{R}^n\) is also called <strong>trajectory</strong>.
  

      </blockquote></i>
      <br>

      <b>Definition 3 — Payoff Functional</b><blockquote><i> A functional of the form
      
        \begin{equation}
        \mathbf{P}[\mathbf{\gamma}] := \int_0^T L(\mathbf{x}(t), \mathbf{\gamma}(t)) dt + \phi(\mathbf{x}(T)),
        \end{equation}
       
        is called a <strong>Payoff Functional</strong>, 
        where the function \(L\) is called <strong>running payoff</strong> or <strong>Lagrangian</strong> 
        and \(\phi\) is called <strong>terminal payoff</strong> or <strong>boundary cost</strong> (sometimes also referred to as Mayer's Term).
        </blockquote></i>
        <br>
  
  

  <b>Definition 4 — Optimal Control Problem</b><blockquote><i> 
    Given a system with controls \(\mathbf{\gamma}\) 
    and payoff functional \(\mathbf{P}[\mathbf{\gamma}]\), 
    the associated <strong>Optimal Control Problem </strong> amounts to finding 
    an <strong>optimal control</strong> \(\mathbf{\gamma}^*\) maximising the payoff: 
    
    \begin{equation}
    \mathbf{P}[\mathbf{\gamma}^*] = \max_{\mathbf{\gamma}\in\Gamma} \mathbf{P}[\mathbf{\gamma}],
    \end{equation}

    that is
    \begin{equation}
    \mathbf{P}[\mathbf{\gamma}^*] \ge \mathbf{P}[\mathbf{\gamma}], \quad \forall \mathbf{\gamma}\in\Gamma.
    \end{equation}

    <br>
    The problem is called a Lagrange problem when \(\phi=0\), and a Mayer problem when \(L=0\).
    When both \(L\ne0\) and \(\phi\ne0\) it is also called a Bolza Problem <a href="#ref1">[1]</a>.

    </blockquote></i>
    <br>

    Real world applications are abundant, from minimising fuel consumption when designing space missions, to optimising the production of chemicals, 
    from maximisation of throughput of information transmition over a communication channel, to the determination of optimal policy paths for monetary policy setting. 
    Even more so, optimality can be considered to a large extent a universal principle of nature, in the sense that
    most processess seem to be optimising over some specific quantity. 
    This is true for nature's fundamentals, where often one can describe physical systems via principles of least action, 
    for biological systems, e.g. explaining animals foraging behaviour, up to societies whose individuals maximise their respective expected utilities.
    Furthermore, optimisaion clearly also plays a crucial role in many 

    
    
    <h2 style="text-align: left;"><b>Dynamic Programming</b></h2>


    <br><br>


    <b>Definition 5 — Bellman's Principle of Optimality</b><blockquote><i> 

      For any point \(\tau>0\) on an optimal trajectory \(\mathbf{x}(t)\), 
      the remaining trajectory \(\mathbf{x}(t>\tau)\) is optimal 
      for the corresponding problem initiated at \(\tau\).
    
    </blockquote></i>

    <br><br>


    Or, in Bellman's own words <a href="#ref2">[2]</a>: 
    <br><br>
    "An optimal policy has the property that whatever 
    the initial state and initial decision are, 
    the remaining decisions must constitute an optimal policy 
    with regard to the state resulting from the first decision."


    <br>




    <h2 style="text-align: left;"><b>Solving the Problem</b></h2>


    <b>Definition x — Hamiltonian</b><blockquote><i> 
      Given a system with controls \(\mathbf{\gamma}\), 
      payoff functional \(\mathbf{P}[\mathbf{\gamma}]\),
      and dynamics of the state variable \(\mathbf{x}\) 
      governed by the law of motion 
      \(\dot{\mathbf{x}}(t)=\mathbf{f}(\mathbf{x}(t), \mathbf{\gamma}(t), t)\)
      
      the <strong>control Hamiltonian</strong> is
      
      \begin{equation}
      H(\mathbf{x}(t), \mathbf{\gamma}(t), \lambda(t), t) := L(\mathbf{x}(t), \mathbf{\gamma}(t), t) +\lambda^T(t)  \mathbf{f}(\mathbf{x}(t), \mathbf{\gamma}(t), t),
      \end{equation}     
      where \(L\) is the Lagrangian term in \(\mathbf{P}\) (running payoff),
      and \(\lambda\) is called the <strong>co-state</strong> variable.
      
    
    </blockquote></i>
    <br>
  Notice that the multiplier (or co-state) \(\lambda(t)\), 
  unlike the Lagrangian multiplier in static optimisation, depends on time </strong><a href="#ref3">[3]</a>.
  <br>



  <br><br>

  <b>Theorem xx — Pontryagin Maximum Principle</b><blockquote><i> 
    Assume the optimal control \(\mathbf{\gamma}^*\) is known and admissable (\(\mathbf{\gamma}^*\in\Gamma\)), 
    which generates the associated optimal trajectory \(\mathbf{x}^*\). 
    Then, there exists and adjoint trajectory \(\mathbf{p}^*\) conjugate to \(\mathbf{x}^*\) 
    such that

    \begin{equation}
    \begin{split}
    \dot{\mathbf{x}}(t) &= \nabla_\lambda H(\mathbf{x}^*, \mathbf{\gamma}^*, \lambda^*, t) \quad\quad\quad\quad \phantom{-} (\text{state equation})\\
    \dot{\lambda}(t) &= -\nabla_\mathbf{x} H(\mathbf{x}^*, \mathbf{\gamma}^*, \lambda^*, t) \quad\quad\quad\quad (\text{co-state equation})\\
     H(\mathbf{x}^*, \mathbf{\gamma}^*, \lambda^*, t) &\ge H(\mathbf{x}^*, \mathbf{\gamma}^*, \lambda, t), \quad \forall \gamma \in \Gamma \quad \phantom{-.} (\text{Pontryagin Maximum Principle})
    \end{split}
    \end{equation}     


  </blockquote></i>
  <br>

  In other words, Pontryagin's Maximum Principle provides a necessary condition for optimality.
  
  <br><br>
  
  <b>Theorem xxx — Transversality Conditions</b><blockquote><i> 
    xxx

  </blockquote></i>
  <br>


  <br><br>




<b>Example 1 — Minimal time for bringing a particle to rest at origin</b>
<br><br>
<i>
Consider the one-dimensional problem of bringing a particle to rest at \(x=0\) in minimal time.
The initial position and velocity of the particle are \(x_0\) and \(v_0\) respectively.

The control is the force \(f(t)\) applied to the particle, such that \(|f(t)|\le 1\).
<br>
Therefore, the problem is to minimise the total time 
\begin{equation}
\mathcal{T} = \int_0^T 1 dt,
\end{equation}
where \(T\) is the time when the particle reaches the origin, subject to the law of motion which,
recalling that \(v=\dot{x}\) and \(f=\dot{v}\), reads
\begin{equation}
 \frac{d}{dt} \begin{bmatrix} x \\ v  \end{bmatrix} = 
\left(\begin{matrix}
     0 & 1 \\
     0 & 0  
   \end{matrix}\right) \begin{bmatrix} x \\ v \end{bmatrix} 
   + \begin{bmatrix} 0 \\ 1 \end{bmatrix} f.
\end{equation}
<br>

To start off, one finds the Hamiltonian to be
\begin{equation}
H = \mathbf{\lambda}^T\left(\begin{matrix}
0 & 1 \\
0 & 0  
\end{matrix}\right) \begin{bmatrix} x \\ v \end{bmatrix} 
+ \mathbf{\lambda}^T \begin{bmatrix} 0 \\ 1 \end{bmatrix} f - 1
= \lambda_1 v + \lambda_2 f - 1.
\end{equation}

Because the term \(\lambda_2 f\) in the Hamiltonian is linear in \(f\), 
the maximum with respect to the control is achieved at one of the endpoints of the interval \([-1, 1]\), depending on the sign of \(\lambda_2\).
That is, the Hamiltonian is maximised by
\begin{equation}
f^*=\begin{cases}
\text{sgn}\left(\lambda_2\right) & \text{if $\lambda_2 \ne 0$}\\
\text{any value} \in {-1,1} & \text{otherwise}
\end{cases} \quad.
\end{equation}
<br>

The costate variables are given by

\begin{equation}
\begin{split}
\dot{\lambda}_1 &= \partial_x H = 0, \\ 
\dot{\lambda}_2 &= \partial_v H = -\lambda_1.
\end{split}
\end{equation}

Denotining the values of the costate variables at termination by \(\bar{\lambda}_i = \lambda_i(t=T)\), 
we can therefore solve for the costate variables:

\begin{equation}
\begin{split}
\lambda_1 &= \bar{\lambda}_1, \\
\lambda_2 &= \bar{\lambda}_1 t + \bar{\lambda}_2.
\end{split}
\end{equation}

Here we observe that on the optimal trajectory, \(\lambda_2\) will switch sign at most once 
before termination at \(t_s=-\bar{\lambda}_2/\bar{\lambda}_1\), 
if \(\text{sgn}\left(\bar{\lambda}_1\right)\ne\text{sgn}\left(\bar{\lambda}_2\right)\). 
This means that the optimal control strategy consists of switching between maximal accelaration in one direction
to maximal acceleration in the opposite direction. This is therefore a bang-bang control.

<br>
Taking this result back to the equations of motion we find

<!-- dx = v -->
\begin{equation}
\begin{split}
\dot{v} &= f^* = \text{sgn}(\bar{\lambda}_1 t+ \bar{\lambda}_2) \\
\dot{x} &= v
\end{split}\quad,
\end{equation}

thus

\begin{equation}
\begin{split}
v &= \text{sgn}(\bar{\lambda}_1 t+ \bar{\lambda}_2) t + v_0\\
x &= \frac{t^2}{2}\text{sgn}(\bar{\lambda}_1 t+ \bar{\lambda}_2) + v_0t + x_0
\end{split}\quad.
\end{equation}

<br><br>

The terminal time \(T\) is free, therefore the transversality condition tells us \(H(t=T)=0\).
Hence, we can conclude that \(|\bar{\lambda}_2| = 1\).
<br>
We can then distinguish four distinct cases.

<ul>
<li> If \(\bar{\lambda}_2=1\) and \(\bar{\lambda}_1\ge 0\), then 
  \begin{equation}
  \begin{split}
  f^* &= 1 \\
  x   &= \frac{t^2}{2} + v_0t + x_0\\
  v   &= t + v_0
  \end{split}
  \end{equation}
</li>
<li>
  If \(\bar{\lambda}_2=1\) and \(\bar{\lambda}_1< 0\), then \(f^*\) can be either \(1\) or \(-1\):
  \begin{equation}
  \begin{split}
  f^* &= 1 \\
  x &= \frac{t^2}{2} + v_0t + x_0\\
  v &= t + v_0
  \end{split}
  \end{equation}
  or
  \begin{equation}
  \begin{split}
  f^* &= -1 \\
  x &= -\frac{t^2}{2} + v_0t + x_0\\
  v &= -t + v_0
  \end{split}
  \end{equation}
</li>
</ul>


</i>

<figure style="text-align: center;justify-content: center;align-items: center;">
  <!-- Create a div where the graph will take place -->
  <div id="my_dataviz"></div>
  <figcaption><i><b>Fig.1:</b> Optimal trajectory of the system described by equation (xx), for different initial conditions (move your mouse to adjust them).
  </i></figcaption>
</figure>

<script src="./vis.js"></script>




<br><br>
  <h4 id="REFERENCES"><i>References and notes</i></h4>

  [1] <a href="https://link.springer.com/article/10.1007/BF02419594" id="ref1">"Über zwei Euler’sche Aufgaben aus der Variationsrechnung", Oskar Bolza, 1913, Annali di Matematica Pura ed Applicata</a>
  <br>
  [2] <a href="https://gwern.net/doc/statistics/decision/1957-bellman-dynamicprogramming.pdf" id="ref2">"Dynamic Programming", Richard Bellman, 1957, Chap. III.3. </a>
  <br>
  [3] <normal id="ref3">Notice that while related, the Control Hamiltonian of optimal control theory is distinct from the Hamiltonian used in mechanics. 
    In particular, the latter is used to derive the equation of motion of a dynamical system. 
    The Hamiltonian of optimal control theory instead, is a concept developed by Lev Pontryagin, 
    with the purpose to provide conditions for extrimising a functional with respect to a control variable. <normal>
  <br>

<!--  https://bookdown.org/egarpor/NP-UC3M/kde-ii-asymp.html-->
<!--  https://bookdown.org/egarpor/NP-EAFIT/intro-nonpar.html-->

<!--  https://bookdown.org/egarpor/inference/-->
<!--  https://bookdown.org/egarpor/PM-UC3M/-->


  <br><br>

  <!-- ________________________________________________________________________________________________ -->
  <!-- ________________________________________________________________________________________________ -->
  <!-- ________________________________________________________________________________________________ -->
  <!--    <h7>-->
  <!-- <span style="float:right;">
 <a href="./L2.html"><b><img src="../Icons/next.png" width="20px" align="right">Next</b></a>
 </span>
 </h7>
 <br> -->

  <h5> <a href="../../Teaching.html"><b><img src="../../Icons/back.png" width="20px"> Back to Teaching</b></a></h5>



  <hr class="w3-opacity">
</div>
</div>
<script type="text/javascript" src="../../js/footer.js"></script>

<!-- End page content -->
</div>

<script src="../../js/OpenCloseSidebar.js"></script>
<!--<script src="../js/ModalImageGallery.js"></script>-->
<script src="../../js/OpenCloseCollapsible.js"></script>

</body>
</html>
